{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA - Tarefa 01: *HAR* com PCA\n",
    "\n",
    "Vamos trabalhar com a base da demonstração feita em aula, mas vamos explorar um pouco melhor como é o desempenho da árvore variando o número de componentes principais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r\"Dados\\UCI\"\n",
    "\n",
    "features_file = os.path.join(folder, \"features.txt\")\n",
    "labels_file = os.path.join(folder, \"activity_labels.txt\")\n",
    "\n",
    "subjtrain_file = os.path.join(folder, \"subject_train.txt\")\n",
    "xtrain_file = os.path.join(folder, \"X_train.txt\")\n",
    "ytrain_file = os.path.join(folder, \"y_train.txt\")\n",
    "\n",
    "subjtest_file = os.path.join(folder, \"subject_test.txt\")\n",
    "xtest_file = os.path.join(folder, \"X_test.txt\")\n",
    "ytest_file = os.path.join(folder, \"y_test.txt\")\n",
    "\n",
    "# Carregando a base features.txt em uma Series\n",
    "features = pd.read_csv(features_file, header=None, names=['nome_var'], sep=\"#\")\n",
    "labels = pd.read_csv(labels_file, delim_whitespace=True, header=None, names=['cod_label', 'label'])\n",
    "\n",
    "subject_train = pd.read_csv(subjtrain_file, header=None, names=['subject_id'])\n",
    "X_train = pd.read_csv(xtrain_file, delim_whitespace=True, header=None, names=features['nome_var'].tolist())\n",
    "y_train = pd.read_csv(ytrain_file, header=None, names=['cod_label'])\n",
    "\n",
    "subject_test = pd.read_csv(subjtest_file, header=None, names=['subject_id'])\n",
    "X_test = pd.read_csv(xtest_file, delim_whitespace=True, header=None, names=features['nome_var'].tolist())\n",
    "y_test = pd.read_csv(ytest_file, header=None, names=['cod_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore de decisão\n",
    "\n",
    "Rode uma árvore de decisão com todas as variáveis, utilizando o ```ccp_alpha=0.001```. Avalie a acurácia nas bases de treinamento e teste. Avalie o tempo de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia treinamento: 97.58\n",
      "Acuracia teste: 87.92\n",
      "CPU times: total: 10.2 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Arvore de decisão com ccp_alpha=0.001\n",
    "tree = DecisionTreeClassifier(ccp_alpha=0.001)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Previsões do modelo\n",
    "y_test_pred = tree.predict(X_test)\n",
    "y_train_pred = tree.predict(X_train)\n",
    "\n",
    "# Acurácia do modelo no conjunto de treinamento e teste\n",
    "acuracia_train = accuracy_score(y_train, y_train_pred)\n",
    "acuracia_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print das acuracias\n",
    "print(f'Acuracia treinamento: {acuracia_train*100:.2f}')\n",
    "print(f'Acuracia teste: {acuracia_test*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore com PCA\n",
    "\n",
    "Faça uma análise de componentes principais das variáveis originais. Utilize apenas uma componente. Faça uma árvore de decisão com esta componente como variável explicativa.\n",
    "\n",
    "- Avalie a acurácia nas bases de treinamento e teste\n",
    "- Avalie o tempo de processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando as bases de treino, teste e validação\n",
    "X_train_pca, X_valida_pca, y_train_pca, y_valida_pca = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.25 s\n",
      "Wall time: 603 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5514, 561)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Inicialmente crio o modelo PCA para poder posteriormente avaliar a acurácia com apenas uma componente\n",
    "prcomp = PCA().fit(X_train_pca)\n",
    "\n",
    "pc_treino = prcomp.transform(X_train_pca)\n",
    "pc_valida = prcomp.transform(X_valida_pca)\n",
    "pc_teste  = prcomp.transform(X_test)\n",
    "\n",
    "pc_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia PCA Treinamento: 49.96\n",
      "Acuracia PCA Validação:   49.02\n",
      "Acuracia PCA Teste:       45.47\n",
      "CPU times: total: 7.22 s\n",
      "Wall time: 7.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Escolhendo a componente\n",
    "n=1\n",
    "\n",
    "colunas = ['cp'+str(x+1) for x in list(range(n))]\n",
    "\n",
    "pc_train = pd.DataFrame(pc_treino[:,:n], columns = colunas)\n",
    "pc_valida = pd.DataFrame(pc_valida [:,:n], columns = colunas)\n",
    "pc_test  = pd.DataFrame( pc_teste[:,:n], columns = colunas)\n",
    "\n",
    "# Criação da arvore e treinamento. Após treinamento, realiza o post-prunning\n",
    "clf = DecisionTreeClassifier(random_state=42).fit(pc_train, y_train_pca)\n",
    "\n",
    "caminho = DecisionTreeClassifier(random_state=42, min_samples_leaf=20).cost_complexity_pruning_path(pc_train, y_train_pca)\n",
    "ccp_alphas, impurities = caminho.ccp_alphas, caminho.impurities\n",
    "\n",
    "ccp_alphas = np.unique(ccp_alphas[ccp_alphas>=0])\n",
    "\n",
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha).fit(pc_train, y_train_pca)\n",
    "    clfs.append(clf)\n",
    "\n",
    "# Calculando as acuracias e printando\n",
    "train_scores = [clf.score(pc_train, y_train_pca) for clf in clfs]\n",
    "valid_scores = [clf.score(pc_valida, y_valida_pca) for clf in clfs]\n",
    "\n",
    "ind_melhor_arvore = len(valid_scores) - valid_scores[::-1].index(max(valid_scores)) - 1\n",
    "melhor_arvore = clfs[ind_melhor_arvore]\n",
    "\n",
    "print(f'Acuracia PCA Treinamento: {train_scores[ind_melhor_arvore]*100:.2f}')\n",
    "print(f'Acuracia PCA Validação:   {valid_scores[ind_melhor_arvore]*100:.2f}')\n",
    "print(f'Acuracia PCA Teste:       {melhor_arvore.score(pc_test, y_test)*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o número de componentes\n",
    "\n",
    "Com base no código acima, teste a árvore de classificação com pelo menos as seguintes possibilidades de quantidades de componentes: ```[1, 2, 5, 10, 50]```. Avalie para cada uma delas:\n",
    "\n",
    "- Acurácia nas bases de treino e teste\n",
    "- Tempo de processamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_de_n = [2, 5, 10, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de execução para n=2: 8.82 segundos\n",
      "Acuracia PCA Treinamento para n=2: 59.10\n",
      "Acuracia PCA Validação para n=2:   46.90\n",
      "Acuracia PCA Teste para n=2:       60.06\n",
      "----------------------------------------\n",
      "Tempo de execução para n=5: 8.73 segundos\n",
      "Acuracia PCA Treinamento para n=5: 90.32\n",
      "Acuracia PCA Validação para n=5:   38.36\n",
      "Acuracia PCA Teste para n=5:       76.93\n",
      "----------------------------------------\n",
      "Tempo de execução para n=10: 16.07 segundos\n",
      "Acuracia PCA Treinamento para n=10: 69.68\n",
      "Acuracia PCA Validação para n=10:   35.53\n",
      "Acuracia PCA Teste para n=10:       77.40\n",
      "----------------------------------------\n",
      "Tempo de execução para n=50: 76.11 segundos\n",
      "Acuracia PCA Treinamento para n=50: 69.68\n",
      "Acuracia PCA Validação para n=50:   35.53\n",
      "Acuracia PCA Teste para n=50:       75.47\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for n in valores_de_n:\n",
    "    colunas = ['cp' + str(x + 1) for x in range(n)]\n",
    "\n",
    "    pc_train = pd.DataFrame(pc_treino[:, :n], columns=colunas)\n",
    "    pc_valida = pd.DataFrame(pc_valida.iloc[:, :n], columns=colunas)\n",
    "    pc_test = pd.DataFrame(pc_teste[:, :n], columns=colunas)\n",
    "\n",
    "    # Inclusão da contagem de tempo para o loop\n",
    "    start_time = time.time()\n",
    "\n",
    "    clf = DecisionTreeClassifier(random_state=42).fit(pc_train, y_train_pca)\n",
    "\n",
    "    caminho = DecisionTreeClassifier(random_state=42, min_samples_leaf=20).cost_complexity_pruning_path(pc_train,\n",
    "                                                                                                           y_train_pca)\n",
    "    ccp_alphas, impurities = caminho.ccp_alphas, caminho.impurities\n",
    "\n",
    "    ccp_alphas = np.unique(ccp_alphas[ccp_alphas >= 0])\n",
    "\n",
    "    clfs = []\n",
    "    for ccp_alpha in ccp_alphas:\n",
    "        clf = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha).fit(pc_train, y_train_pca)\n",
    "        clfs.append(clf)\n",
    "\n",
    "    # Termino da contagem de tempo\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculando as acuracias\n",
    "    train_scores = [clf.score(pc_train, y_train_pca) for clf in clfs]\n",
    "    valid_scores = [clf.score(pc_valida, y_valida_pca) for clf in clfs]\n",
    "\n",
    "    # Encontrando o índice da melhor árvore durante a validação\n",
    "    ind_melhor_arvore = np.argmax(valid_scores)\n",
    "\n",
    "    # Se o ind_melhor_arvore for 0, então estamos usando o modelo sem poda\n",
    "    if ind_melhor_arvore == 0:\n",
    "        melhor_arvore = clfs[0]\n",
    "    else:\n",
    "        melhor_arvore = clfs[ind_melhor_arvore - 1]\n",
    "    \n",
    "    print(f'Tempo de execução para n={n}: {end_time - start_time:.2f} segundos')\n",
    "    print(f'Acuracia PCA Treinamento para n={n}: {train_scores[ind_melhor_arvore] * 100:.2f}')\n",
    "    print(f'Acuracia PCA Validação para n={n}:   {valid_scores[ind_melhor_arvore] * 100:.2f}')\n",
    "    print(f'Acuracia PCA Teste para n={n}:       {melhor_arvore.score(pc_test, y_test) * 100:.2f}')\n",
    "    print('-' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclua\n",
    "\n",
    "- O que aconteceu com a acurácia?\n",
    "- O que aconteceu com o tempo de processamento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Conteúdo",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
